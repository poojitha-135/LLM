{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCdHjBsoEqDF0JGhW3X1bM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojitha-135/LLM/blob/main/exp4(llm).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4a. Named Entity Recognition\n",
        "from tensorflow.keras.datasets import imdb\n",
        "# Load IMDb dataset with limited vocabulary\n",
        "(train_data, _), _ = imdb.load_data(num_words=1000)\n",
        "# Obtain word index dictionary\n",
        "index_map = imdb.get_word_index()\n",
        "# Create reverse mapping to decode integers to words\n",
        "index_to_word = {}\n",
        "for word, index in index_map.items():\n",
        "    index_to_word[index + 3] = word\n",
        "index_to_word[0] = \"<PAD>\"\n",
        "index_to_word[1] = \"<START>\"\n",
        "index_to_word[2] = \"<UNK>\"\n",
        "# Function to convert encoded review into text\n",
        "def convert_to_text(encoded_review):\n",
        "    decoded_words = []\n",
        "    for num in encoded_review:\n",
        "        decoded_words.append(index_to_word.get(num, \"?\"))\n",
        "    return \" \".join(decoded_words)\n",
        "# Simple rule-based entity recognizer\n",
        "def identify_entities(sentence):\n",
        "    print(\"\\nNamed Entity Recognition Output:\\n\")\n",
        "    for token in sentence.split():\n",
        "        if token.isupper():\n",
        "            print(token, \"-> Entity\")\n",
        "        elif len(token) >= 8:\n",
        "            print(token, \"-> Entity\")\n",
        "        else:\n",
        "            print(token, \"-> Non-Entity\")\n",
        "# ------MAIN--------\n",
        "review_id = int(input(\"Enter IMDb review number (0–24999): \"))\n",
        "# Decode selected review\n",
        "decoded_review = convert_to_text(train_data[review_id])\n",
        "# Display partial review\n",
        "print(\"\\nSelected IMDb Review (partial):\\n\")\n",
        "print(decoded_review[:300], \"...\")\n",
        "# Perform Named Entity Recognition\n",
        "identify_entities(decoded_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SOccDBy2ydx",
        "outputId": "019db873-6a94-436c-ca8d-2650fbfd0d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter IMDb review number (0–24999): 8\n",
            "\n",
            "Selected IMDb Review (partial):\n",
            "\n",
            "<START> just got out and cannot believe what a brilliant documentary this is <UNK> do you <UNK> out of a movie theater in such <UNK> and <UNK> <UNK> movies have become so over <UNK> that the <UNK> of <UNK> something truly special and unique <UNK> happens <UNK> <UNK> did this to me when it first came ...\n",
            "\n",
            "Named Entity Recognition Output:\n",
            "\n",
            "<START> -> Entity\n",
            "just -> Non-Entity\n",
            "got -> Non-Entity\n",
            "out -> Non-Entity\n",
            "and -> Non-Entity\n",
            "cannot -> Non-Entity\n",
            "believe -> Non-Entity\n",
            "what -> Non-Entity\n",
            "a -> Non-Entity\n",
            "brilliant -> Entity\n",
            "documentary -> Entity\n",
            "this -> Non-Entity\n",
            "is -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "do -> Non-Entity\n",
            "you -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "out -> Non-Entity\n",
            "of -> Non-Entity\n",
            "a -> Non-Entity\n",
            "movie -> Non-Entity\n",
            "theater -> Non-Entity\n",
            "in -> Non-Entity\n",
            "such -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "and -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "<UNK> -> Entity\n",
            "movies -> Non-Entity\n",
            "have -> Non-Entity\n",
            "become -> Non-Entity\n",
            "so -> Non-Entity\n",
            "over -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "that -> Non-Entity\n",
            "the -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "of -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "something -> Entity\n",
            "truly -> Non-Entity\n",
            "special -> Non-Entity\n",
            "and -> Non-Entity\n",
            "unique -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "happens -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "<UNK> -> Entity\n",
            "did -> Non-Entity\n",
            "this -> Non-Entity\n",
            "to -> Non-Entity\n",
            "me -> Non-Entity\n",
            "when -> Non-Entity\n",
            "it -> Non-Entity\n",
            "first -> Non-Entity\n",
            "came -> Non-Entity\n",
            "out -> Non-Entity\n",
            "and -> Non-Entity\n",
            "this -> Non-Entity\n",
            "movie -> Non-Entity\n",
            "is -> Non-Entity\n",
            "doing -> Non-Entity\n",
            "to -> Non-Entity\n",
            "me -> Non-Entity\n",
            "now -> Non-Entity\n",
            "i -> Non-Entity\n",
            "didn't -> Non-Entity\n",
            "know -> Non-Entity\n",
            "a -> Non-Entity\n",
            "thing -> Non-Entity\n",
            "about -> Non-Entity\n",
            "this -> Non-Entity\n",
            "before -> Non-Entity\n",
            "going -> Non-Entity\n",
            "into -> Non-Entity\n",
            "it -> Non-Entity\n",
            "and -> Non-Entity\n",
            "what -> Non-Entity\n",
            "a -> Non-Entity\n",
            "surprise -> Entity\n",
            "if -> Non-Entity\n",
            "you -> Non-Entity\n",
            "hear -> Non-Entity\n",
            "the -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "you -> Non-Entity\n",
            "might -> Non-Entity\n",
            "get -> Non-Entity\n",
            "the -> Non-Entity\n",
            "feeling -> Non-Entity\n",
            "that -> Non-Entity\n",
            "this -> Non-Entity\n",
            "is -> Non-Entity\n",
            "one -> Non-Entity\n",
            "of -> Non-Entity\n",
            "those -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "movies -> Non-Entity\n",
            "about -> Non-Entity\n",
            "an -> Non-Entity\n",
            "amazing -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "<UNK> -> Entity\n",
            "with -> Non-Entity\n",
            "over -> Non-Entity\n",
            "the -> Non-Entity\n",
            "top -> Non-Entity\n",
            "music -> Non-Entity\n",
            "and -> Non-Entity\n",
            "trying -> Non-Entity\n",
            "to -> Non-Entity\n",
            "have -> Non-Entity\n",
            "us -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "<UNK> -> Entity\n",
            "of -> Non-Entity\n",
            "what -> Non-Entity\n",
            "a -> Non-Entity\n",
            "great -> Non-Entity\n",
            "story -> Non-Entity\n",
            "it -> Non-Entity\n",
            "is -> Non-Entity\n",
            "telling -> Non-Entity\n",
            "but -> Non-Entity\n",
            "then -> Non-Entity\n",
            "not -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "us -> Non-Entity\n",
            "in -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "this -> Non-Entity\n",
            "is -> Non-Entity\n",
            "not -> Non-Entity\n",
            "that -> Non-Entity\n",
            "movie -> Non-Entity\n",
            "the -> Non-Entity\n",
            "people -> Non-Entity\n",
            "tell -> Non-Entity\n",
            "the -> Non-Entity\n",
            "story -> Non-Entity\n",
            "this -> Non-Entity\n",
            "does -> Non-Entity\n",
            "such -> Non-Entity\n",
            "a -> Non-Entity\n",
            "good -> Non-Entity\n",
            "job -> Non-Entity\n",
            "of -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "every -> Non-Entity\n",
            "moment -> Non-Entity\n",
            "of -> Non-Entity\n",
            "their -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "while -> Non-Entity\n",
            "we -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "their -> Non-Entity\n",
            "world -> Non-Entity\n",
            "and -> Non-Entity\n",
            "feel -> Non-Entity\n",
            "every -> Non-Entity\n",
            "second -> Non-Entity\n",
            "with -> Non-Entity\n",
            "them -> Non-Entity\n",
            "there -> Non-Entity\n",
            "is -> Non-Entity\n",
            "so -> Non-Entity\n",
            "much -> Non-Entity\n",
            "beyond -> Non-Entity\n",
            "the -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "that -> Non-Entity\n",
            "makes -> Non-Entity\n",
            "everything -> Entity\n",
            "they -> Non-Entity\n",
            "go -> Non-Entity\n",
            "through -> Non-Entity\n",
            "so -> Non-Entity\n",
            "much -> Non-Entity\n",
            "more -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "<UNK> -> Entity\n",
            "the -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "was -> Non-Entity\n",
            "also -> Non-Entity\n",
            "a -> Non-Entity\n",
            "great -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "about -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "<UNK> -> Entity\n",
            "and -> Non-Entity\n",
            "showing -> Non-Entity\n",
            "the -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "in -> Non-Entity\n",
            "an -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "way -> Non-Entity\n",
            "but -> Non-Entity\n",
            "this -> Non-Entity\n",
            "film -> Non-Entity\n",
            "is -> Non-Entity\n",
            "much -> Non-Entity\n",
            "more -> Non-Entity\n",
            "of -> Non-Entity\n",
            "a -> Non-Entity\n",
            "human -> Non-Entity\n",
            "story -> Non-Entity\n",
            "i -> Non-Entity\n",
            "just -> Non-Entity\n",
            "saw -> Non-Entity\n",
            "it -> Non-Entity\n",
            "today -> Non-Entity\n",
            "but -> Non-Entity\n",
            "i -> Non-Entity\n",
            "will -> Non-Entity\n",
            "go -> Non-Entity\n",
            "and -> Non-Entity\n",
            "say -> Non-Entity\n",
            "that -> Non-Entity\n",
            "this -> Non-Entity\n",
            "is -> Non-Entity\n",
            "one -> Non-Entity\n",
            "of -> Non-Entity\n",
            "the -> Non-Entity\n",
            "best -> Non-Entity\n",
            "<UNK> -> Entity\n",
            "i -> Non-Entity\n",
            "have -> Non-Entity\n",
            "ever -> Non-Entity\n",
            "seen -> Non-Entity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4b. Text summerization\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from collections import Counter\n",
        "# Load IMDb dataset\n",
        "(X_train, _), _ = imdb.load_data(num_words=1000)\n",
        "# Get word index\n",
        "word_index = imdb.get_word_index()\n",
        "# Reverse mapping with offset handling\n",
        "reverse_word_index = {value + 3: key for key, value in word_index.items()}\n",
        "reverse_word_index[0] = \"<PAD>\"\n",
        "reverse_word_index[1] = \"<START>\"\n",
        "reverse_word_index[2] = \"<UNK>\"\n",
        "# Decode review function\n",
        "def decode_review(review):\n",
        "    return \" \".join([reverse_word_index.get(i, \"?\") for i in review])\n",
        "# -------- USER INPUT --------\n",
        "review_no = int(input(\"Enter IMDb review number (0–24999): \"))\n",
        "review_text = decode_review(X_train[review_no])\n",
        "words = review_text.split()\n",
        "# Frequency-based extractive summarization\n",
        "freq = Counter(words)\n",
        "summary = \" \".join([word for word, _ in freq.most_common(15)])\n",
        "# Output\n",
        "print(\"\\nSelected IMDb Review (partial):\\n\")\n",
        "print(review_text[:300], \"...\")\n",
        "print(\"\\nSummary:\\n\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJnN2VF7Rjux",
        "outputId": "c4df80b1-87db-4b68-df95-ba998bcfdc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter IMDb review number (0–24999): 18\n",
            "\n",
            "Selected IMDb Review (partial):\n",
            "\n",
            "<START> i have only had the <UNK> of seeing this movie once when i was rather young so much of the movie is <UNK> in trying to remember it however i can say it was not as funny as a movie called killer <UNK> should have been and the most memorable things from this movie are the song and the scene wi ...\n",
            "\n",
            "Summary:\n",
            "\n",
            "<UNK> a the movie and to of this as i have was is however not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4c. Question Answering\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 1000\n",
        "max_len = 100\n",
        "# Load IMDb data\n",
        "(X_train, y_train), _ = imdb.load_data(num_words=vocab_size)\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "# Build model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 64, input_length=max_len),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(X_train, y_train, epochs=2, batch_size=128, validation_split=0.2)\n",
        "# ---- USER INPUT FIX ----\n",
        "word_index = imdb.get_word_index()\n",
        "def encode_review(text):\n",
        "    encoded = []\n",
        "    for word in text.lower().split():\n",
        "        idx = word_index.get(word)\n",
        "        if idx is not None:\n",
        "            idx = idx + 3   # IMPORTANT FIX\n",
        "            if idx < vocab_size:\n",
        "                encoded.append(idx)\n",
        "        else:\n",
        "            encoded.append(2)  # <UNK>\n",
        "    return pad_sequences([encoded], maxlen=max_len)\n",
        "# User input\n",
        "user_review = input(\"\\nEnter a movie review: \")\n",
        "encoded_review = encode_review(user_review)\n",
        "prediction = model.predict(encoded_review)[0][0]\n",
        "print(\"\\nQuestion: Is the review positive?\")\n",
        "if prediction >= 0.6:\n",
        "    print(\"Answer: Yes (Positive)\")\n",
        "else:\n",
        "    print(\"Answer: No (Negative)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5oquB12R1m8",
        "outputId": "3ee934bd-9efb-4b65-dea1-9e783153b535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6200 - loss: 0.6676 - val_accuracy: 0.7826 - val_loss: 0.5001\n",
            "Epoch 2/2\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4585 - val_accuracy: 0.8078 - val_loss: 0.4102\n",
            "\n",
            "Enter a movie review: movie is very good\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "Question: Is the review positive?\n",
            "Answer: Yes (Positive)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_D91LEOCTfnk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}