{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqqr66uJnsTc",
        "outputId": "74c02f45-73d3-44b3-8718-57a84a56bbe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence:  implement and visualize the self-attention\n",
            "\n",
            "Attention Scores:\n",
            "tensor([[3.2309, 2.3598, 2.2143, 1.4250, 1.6198],\n",
            "        [2.3598, 2.2646, 1.7407, 1.5350, 1.5737],\n",
            "        [2.2143, 1.7407, 2.0908, 0.8100, 1.3129],\n",
            "        [1.4250, 1.5350, 0.8100, 1.8287, 0.9937],\n",
            "        [1.6198, 1.5737, 1.3129, 0.9937, 1.5282]])\n",
            "\n",
            "Attention Weights:\n",
            "tensor([[0.4664, 0.1952, 0.1687, 0.0766, 0.0931],\n",
            "        [0.2993, 0.2721, 0.1611, 0.1312, 0.1363],\n",
            "        [0.3166, 0.1972, 0.2799, 0.0777, 0.1286],\n",
            "        [0.2082, 0.2324, 0.1125, 0.3117, 0.1352],\n",
            "        [0.2417, 0.2308, 0.1778, 0.1292, 0.2205]])\n",
            "\n",
            "Context Vectors:\n",
            "Context vector for implement :\n",
            "tensor([0.4195, 0.7229, 0.1106, 0.4035, 0.6110, 0.6311, 0.6922, 0.2507])\n",
            "Context vector for and :\n",
            "tensor([0.3366, 0.7045, 0.1426, 0.3569, 0.4938, 0.6312, 0.6435, 0.3254])\n",
            "Context vector for visualize :\n",
            "tensor([0.3793, 0.7456, 0.1149, 0.4192, 0.5391, 0.5423, 0.6438, 0.2860])\n",
            "Context vector for the :\n",
            "tensor([0.2529, 0.5848, 0.2197, 0.2913, 0.4185, 0.6894, 0.5716, 0.4233])\n",
            "Context vector for self-attention :\n",
            "tensor([0.3100, 0.7249, 0.1502, 0.3618, 0.4408, 0.6075, 0.5869, 0.3225])\n"
          ]
        }
      ],
      "source": [
        "#2a self attention\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "# Read sentence from user\n",
        "sentence = input(\"Enter a sentence: \")\n",
        "# Split sentence into words\n",
        "tokens = sentence.split()\n",
        "# Generate random embeddings for tokens\n",
        "embeddings = torch.rand(len(tokens), 8)\n",
        "# Assign embeddings as Query, Key, and Value\n",
        "Q = embeddings\n",
        "K = embeddings\n",
        "V = embeddings\n",
        "# Compute attention score matrix\n",
        "scores = torch.matmul(Q, K.T)\n",
        "# Convert scores into attention weights\n",
        "weights = F.softmax(scores, dim=1)\n",
        "# Compute context vectors\n",
        "context = torch.matmul(weights, V)\n",
        "# Display attention scores\n",
        "print(\"\\nAttention Scores:\")\n",
        "print(scores)\n",
        "# Display attention weights\n",
        "print(\"\\nAttention Weights:\")\n",
        "print(weights)\n",
        "# Display context vector for each word\n",
        "print(\"\\nContext Vectors:\")\n",
        "for i in range(len(tokens)):\n",
        "    print(\"Context vector for\", tokens[i], \":\")\n",
        "    print(context[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2b multi head attention\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "# Input sentence\n",
        "sentence = input(\"Enter a sentence: \")\n",
        "# Tokenize sentence\n",
        "tokens = sentence.split()\n",
        "# Create embeddings\n",
        "embeddings = torch.rand(len(tokens), 8)\n",
        "# Number of attention heads\n",
        "heads = 2\n",
        "head_size = embeddings.size(1) // heads\n",
        "# Apply attention for each head\n",
        "for h in range(heads):\n",
        "    print(\"\\n========== Head\", h + 1, \"==========\")\n",
        "    # Split embeddings for current head\n",
        "    Q = embeddings[:, h*head_size:(h+1)*head_size]\n",
        "    K = Q\n",
        "    V = Q\n",
        "    # Compute attention scores\n",
        "    scores = torch.matmul(Q, K.T)\n",
        "    # Normalize scores\n",
        "    weights = F.softmax(scores, dim=1)\n",
        "    # Compute context vectors\n",
        "    context = torch.matmul(weights, V)\n",
        "    print(\"\\nAttention Scores:\")\n",
        "    print(scores)\n",
        "    print(\"Attention Weights:\")\n",
        "    print(weights)\n",
        "    print(\"Context Vectors:\")\n",
        "    for i in range(len(tokens)):\n",
        "        print(\"Context vector for\", tokens[i], \"(Head\", h + 1, \"):\")\n",
        "        print(context[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt66KJAPoqhL",
        "outputId": "51e7e788-7b88-413b-98b9-906057d04e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: implement and visualize the self-attention\n",
            "\n",
            "========== Head 1 ==========\n",
            "\n",
            "Attention Scores:\n",
            "tensor([[0.7635, 0.8743, 0.4070, 0.4805, 0.4366],\n",
            "        [0.8743, 1.1107, 0.3921, 0.3841, 0.6614],\n",
            "        [0.4070, 0.3921, 0.6678, 0.5614, 0.3520],\n",
            "        [0.4805, 0.3841, 0.5614, 0.7479, 0.1520],\n",
            "        [0.4366, 0.6614, 0.3520, 0.1520, 0.6195]])\n",
            "Attention Weights:\n",
            "tensor([[0.2330, 0.2603, 0.1631, 0.1756, 0.1680],\n",
            "        [0.2323, 0.2942, 0.1434, 0.1423, 0.1878],\n",
            "        [0.1853, 0.1826, 0.2405, 0.2162, 0.1754],\n",
            "        [0.1992, 0.1809, 0.2160, 0.2603, 0.1435],\n",
            "        [0.1952, 0.2444, 0.1793, 0.1468, 0.2343]])\n",
            "Context Vectors:\n",
            "Context vector for implement (Head 1 ):\n",
            "tensor([0.4460, 0.3164, 0.4857, 0.1931])\n",
            "Context vector for and (Head 1 ):\n",
            "tensor([0.4216, 0.3278, 0.5242, 0.1813])\n",
            "Context vector for visualize (Head 1 ):\n",
            "tensor([0.4646, 0.3239, 0.3889, 0.2302])\n",
            "Context vector for the (Head 1 ):\n",
            "tensor([0.4947, 0.3021, 0.3818, 0.2234])\n",
            "Context vector for self-attention (Head 1 ):\n",
            "tensor([0.4072, 0.3493, 0.4760, 0.1983])\n",
            "\n",
            "========== Head 2 ==========\n",
            "\n",
            "Attention Scores:\n",
            "tensor([[1.3288, 0.9926, 1.4019, 0.4419, 1.3610],\n",
            "        [0.9926, 0.8071, 1.1694, 0.3910, 1.2137],\n",
            "        [1.4019, 1.1694, 1.7845, 0.4821, 1.6234],\n",
            "        [0.4419, 0.3910, 0.4821, 0.4209, 0.9039],\n",
            "        [1.3610, 1.2137, 1.6234, 0.9039, 2.4191]])\n",
            "Attention Weights:\n",
            "tensor([[0.2361, 0.1687, 0.2540, 0.0973, 0.2439],\n",
            "        [0.2075, 0.1724, 0.2476, 0.1137, 0.2588],\n",
            "        [0.2039, 0.1616, 0.2989, 0.0813, 0.2544],\n",
            "        [0.1799, 0.1710, 0.1873, 0.1762, 0.2856],\n",
            "        [0.1498, 0.1293, 0.1947, 0.0948, 0.4315]])\n",
            "Context Vectors:\n",
            "Context vector for implement (Head 2 ):\n",
            "tensor([0.6381, 0.4383, 0.7383, 0.3476])\n",
            "Context vector for and (Head 2 ):\n",
            "tensor([0.6315, 0.4273, 0.7307, 0.3697])\n",
            "Context vector for visualize (Head 2 ):\n",
            "tensor([0.6643, 0.4301, 0.7542, 0.3502])\n",
            "Context vector for the (Head 2 ):\n",
            "tensor([0.5875, 0.4117, 0.6951, 0.4227])\n",
            "Context vector for self-attention (Head 2 ):\n",
            "tensor([0.6307, 0.4122, 0.7804, 0.5151])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YQNkc76slTx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}